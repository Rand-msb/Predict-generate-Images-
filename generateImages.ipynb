{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAUSeapqPsrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Exercise 2: Train a VAE to generate images similar to the images of the given fashion-mnist dataset. \n",
        "\n",
        "The dataset is given in two csv files (train and test). ALL data should be used to train the VAE. The csv files have headers, their first columns contain labels, and the remaining columns contain image data.\n",
        "\n",
        "Your should: write dataloaders, train an appropriate VAE, show a few samples and their corresponding decoded images, as well as a few of the generated samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLW1J8EnzEur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feca61b0-cc71-41c2-da3f-c216e7162922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-16 16:56:19--  https://www.dropbox.com/s/tzs174hrjs1rbzs/FashionMNIST.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/tzs174hrjs1rbzs/FashionMNIST.zip [following]\n",
            "--2023-01-16 16:56:19--  https://www.dropbox.com/s/raw/tzs174hrjs1rbzs/FashionMNIST.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com/cd/0/inline/B0q3tqiCpLKzsfD_Q2U8HOPGd4wHCWO7mBVIN6NohPAurmaV0Kox23X_igoiZUItfZ4WbKWTmaqIpmdYoI3QR1Nw4RU_-67PeaC8xk5b2ce1wlk0oNMttQjhJZsxliGpczkH4McQSvA99v61KN3_yQN0MiinPU1z8gbZctxNe_1SuQ/file# [following]\n",
            "--2023-01-16 16:56:19--  https://uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com/cd/0/inline/B0q3tqiCpLKzsfD_Q2U8HOPGd4wHCWO7mBVIN6NohPAurmaV0Kox23X_igoiZUItfZ4WbKWTmaqIpmdYoI3QR1Nw4RU_-67PeaC8xk5b2ce1wlk0oNMttQjhJZsxliGpczkH4McQSvA99v61KN3_yQN0MiinPU1z8gbZctxNe_1SuQ/file\n",
            "Resolving uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com (uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com)... 162.125.4.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com (uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B0qd2VTxrN8J4fu8-38ZWcYKzQ5kDM4b8t7BnoV2uTaj81OW8p1Z7-Ut_cKLt8U5682HUBGkeBEZDS6LnD-zCnl6lwyHG86hRL_w2NGOkFEideBOMgj512FHgYiJyG5OuNZ05udJ368J6Z9aI4K43dA1YoLGXx7HX-cNnXvW6qlVqPHiwqhRzvfOz8JyI44e0LfUa3B57UZ4Mf3gHe5_T6ZkmHvo9NXrq7b3WtDyzg9w2wBMlRUuiK4UIB4u3ZQDXe2A7Z9W4TaRsQlz7a0h0x3DlQVzxdWsDARkamGJkTTc5MzJePKr76_O3LvwJq2R-yATZ9CvlfHZS0nHxt34fMbsltF92nw-3ZzbEFRCml3zlMaiQL0ikBhvi6-ShdT6Mo0Bgwfgmi3luQZCgolUzgUNsv3u1yphIii0hF7gw2LjOw/file [following]\n",
            "--2023-01-16 16:56:20--  https://uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com/cd/0/inline2/B0qd2VTxrN8J4fu8-38ZWcYKzQ5kDM4b8t7BnoV2uTaj81OW8p1Z7-Ut_cKLt8U5682HUBGkeBEZDS6LnD-zCnl6lwyHG86hRL_w2NGOkFEideBOMgj512FHgYiJyG5OuNZ05udJ368J6Z9aI4K43dA1YoLGXx7HX-cNnXvW6qlVqPHiwqhRzvfOz8JyI44e0LfUa3B57UZ4Mf3gHe5_T6ZkmHvo9NXrq7b3WtDyzg9w2wBMlRUuiK4UIB4u3ZQDXe2A7Z9W4TaRsQlz7a0h0x3DlQVzxdWsDARkamGJkTTc5MzJePKr76_O3LvwJq2R-yATZ9CvlfHZS0nHxt34fMbsltF92nw-3ZzbEFRCml3zlMaiQL0ikBhvi6-ShdT6Mo0Bgwfgmi3luQZCgolUzgUNsv3u1yphIii0hF7gw2LjOw/file\n",
            "Reusing existing connection to uc21e8eb1102cb91293ef433f7f8.dl-eu.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72114846 (69M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  68.77M  26.2MB/s    in 2.6s    \n",
            "\n",
            "2023-01-16 16:56:24 (26.2 MB/s) - ‘data.zip’ saved [72114846/72114846]\n",
            "\n",
            "Archive:  data.zip\n",
            "  inflating: fashion-mnist_test.csv  \n",
            "  inflating: fashion-mnist_train.csv  \n",
            "  inflating: t10k-images-idx3-ubyte  \n",
            "  inflating: t10k-labels-idx1-ubyte  \n",
            "  inflating: train-images-idx3-ubyte  \n",
            "  inflating: train-labels-idx1-ubyte  \n"
          ]
        }
      ],
      "source": [
        "!wget -O data.zip https://www.dropbox.com/s/tzs174hrjs1rbzs/FashionMNIST.zip?dl=0\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThnJg32TKQYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25bf7ee6-c6b4-411a-b534-7129b4d0c3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy \n",
        "df1=pd.read_csv(\"/content/fashion-mnist_test.csv\" , header=None)\n",
        "df2=pd.read_csv(\"/content/fashion-mnist_train.csv\" , header=None)\n",
        "df1=df1.to_numpy()\n",
        "df2=df2.to_numpy()\n",
        "df1=numpy.delete(df1,0,axis=0)\n",
        "df1=numpy.delete(df1,0,axis=1)\n",
        "df2=numpy.delete(df2,0,axis=0)\n",
        "df2=numpy.delete(df2,0,axis=1)\n",
        "DATA = numpy.concatenate((df1,df2))\n",
        "# df3=pd.concat([df1,df2],axis=1)\n",
        "# df3.to_csv(\"../content/sample_data/all.csv\",index=False) #save to file\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HitSr1bgnFAG",
        "outputId": "d2aa9140-339a-4282-9760-2735783d03a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['0', '0', '0', ..., '0', '0', '0'],\n",
              "       ['0', '0', '0', ..., '0', '0', '0'],\n",
              "       ['0', '0', '0', ..., '0', '0', '0'],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PF9u4ZZjjTfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jobKLvScivPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "usqOfD3nivRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transform\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "\n",
        "class VAN(Dataset):\n",
        "  def __init__(self, File):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.X = File.astype(numpy.float32).reshape(-1,28,28)/255.0  # creaing the image from vectors to image . -1 i don't know the number of the sample\n",
        "    # self.Y=df_y.iloc[:,0].to_numpy()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__ (self,idx):\n",
        "    image= self.X[idx]\n",
        "    image = torch.tensor(numpy.expand_dims(image,axis=0))\n",
        "\n",
        "\n",
        "    # lable = torch.tensor(self.Y[idx])\n",
        "    return image\n",
        "    # ,lable\n"
      ],
      "metadata": {
        "id": "a25ecQDAecJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = VAN(DATA)\n",
        "batch_sz = 64\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_sz, shuffle=True)\n",
        "#Iterater \n",
        "dataiter = iter(train_loader)\n",
        "images = next(dataiter)\n",
        "\n",
        "#images.shape = Batch size X GreyScale (Single value per pixel) X #Pixels X #Pixels\n",
        "#labels.shape = ????\n",
        "print(images.shape)\n",
        "type(images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_HgV3_ffXBb",
        "outputId": "54f09ab2-0a0d-4191-a2d5-f8e8cc4789b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VarAutoEncoder(nn.Module):\n",
        "  def __init__(self, nz):\n",
        "    super().__init__()\n",
        "    self.nz = nz\n",
        "    self.econv1 = nn.Conv2d(1, 16, 3, 2, 1)\n",
        "    self.ebn1 = nn.BatchNorm2d(16)\n",
        "    self.econv2 = nn.Conv2d(16, 32, 3, 2, 1)\n",
        "    self.ebn2 = nn.BatchNorm2d(32)\n",
        "    self.econv3 = nn.Conv2d(32,64, 3, 2, 1)\n",
        "    self.ebn3 = nn.BatchNorm2d(64)\n",
        "    self.elinear1 = nn.Linear(64*4*4, 128)\n",
        "    self.ebn4 = nn.BatchNorm1d(128)\n",
        "    \n",
        "    self.dlinear1 = nn.Linear(nz,128)\n",
        "    self.dbn1 = nn.BatchNorm1d(128)\n",
        "    self.dlinear2 = nn.Linear(128,64*4*4)\n",
        "    self.dbn2 = nn.BatchNorm2d(64)\n",
        "    self.dconv1 = nn.ConvTranspose2d(64, 32, 3, 2, 1)\n",
        "    self.dbn3 = nn.BatchNorm2d(32)\n",
        "    self.dconv2 = nn.ConvTranspose2d(32, 16, 3, 2, 1, output_padding =1)\n",
        "    self.dbn4 = nn.BatchNorm2d(16)\n",
        "    self.dconv3 = nn.ConvTranspose2d(16, 1, 3, 2, 1, output_padding =1)\n",
        "    \n",
        "    self.ulinear = nn.Linear(128,nz)\n",
        "    self.slinear = nn.Linear(128,nz)\n",
        "\n",
        "\n",
        "  def encoder (self,x):\n",
        "    x=x.view(-1,1,28,28)\n",
        "    print(\"i am here\")\n",
        "    print(x.shape)\n",
        "    x = F.leaky_relu(self.econv1(x))\n",
        "    print(\"i am here2\")\n",
        "\n",
        "    x = self.ebn1(x)\n",
        "    x = F.leaky_relu(self.econv2(x))\n",
        "    print(\"i am here3\")\n",
        "\n",
        "    x = self.ebn2(x)\n",
        "    x = F.leaky_relu(self.econv3(x))\n",
        "    x = self.ebn3(x)\n",
        "    x = x.view(-1,64*4*4)\n",
        "    print(\"i am here5\")\n",
        "\n",
        "    x = F.leaky_relu(self.elinear1(x))\n",
        "    print(\"here is the shape of it \")\n",
        "    print(x.shape)\n",
        "\n",
        "    x = self.ebn4(x)\n",
        "\n",
        "\n",
        "    return x\n",
        "  \n",
        "  def decoder(self, x):\n",
        "    x = F.leaky_relu(self.dlinear1(x))\n",
        "    x = self.dbn1(x)\n",
        "    x = F.leaky_relu(self.dlinear2(x))\n",
        "    x = x.view(-1, 64,4,4)\n",
        "    x = self.dbn2(x)\n",
        "    x = F.leaky_relu(self.dconv1(x))\n",
        "    x = self.dbn3(x)\n",
        "    x = F.leaky_relu(self.dconv2(x))\n",
        "    x = self.dbn4(x)\n",
        "    x = torch.sigmoid(self.dconv3(x))\n",
        "    return x\n",
        "\n",
        "  def get_params(self,x):\n",
        "    u = self.ulinear(x)\n",
        "    logvar = self.slinear(x)\n",
        "    return u, logvar\n",
        "\n",
        "  def reparametarization(self, u, logvar):\n",
        "    std = torch.exp(logvar/2)\n",
        "    z = u + std*torch.randn_like(u)\n",
        "    return z\n",
        "\n",
        "  def forward(self,x):\n",
        "    ex = self.encoder(x)\n",
        "    print(\"i am here99\")\n",
        "\n",
        "    u, logvar = self.get_params(ex)\n",
        "    print(\"i am here909\")\n",
        "\n",
        "    z = self.reparametarization(u, logvar)\n",
        "\n",
        "    x = self.decoder(z)\n",
        "    return ex,z, x, u, logvar "
      ],
      "metadata": {
        "id": "6UwtkS3Wpup6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "net = VarAutoEncoder(32)\n",
        "net = VarAutoEncoder(32).to(device)\n",
        "summary(net,(1,28,28))\n",
        "# for batch in train_loader:\n",
        "#     X = batch[0][0].to(device)\n",
        "#     print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLU2OCn7ppvr",
        "outputId": "d4abbea4-31b4-4b04-a3cb-7e8b5a2a6aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am here\n",
            "torch.Size([2, 1, 28, 28])\n",
            "i am here2\n",
            "i am here3\n",
            "i am here5\n",
            "here is the shape of it \n",
            "torch.Size([2, 128])\n",
            "i am here99\n",
            "i am here909\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 14, 14]             160\n",
            "       BatchNorm2d-2           [-1, 16, 14, 14]              32\n",
            "            Conv2d-3             [-1, 32, 7, 7]           4,640\n",
            "       BatchNorm2d-4             [-1, 32, 7, 7]              64\n",
            "            Conv2d-5             [-1, 64, 4, 4]          18,496\n",
            "       BatchNorm2d-6             [-1, 64, 4, 4]             128\n",
            "            Linear-7                  [-1, 128]         131,200\n",
            "       BatchNorm1d-8                  [-1, 128]             256\n",
            "            Linear-9                   [-1, 32]           4,128\n",
            "           Linear-10                   [-1, 32]           4,128\n",
            "           Linear-11                  [-1, 128]           4,224\n",
            "      BatchNorm1d-12                  [-1, 128]             256\n",
            "           Linear-13                 [-1, 1024]         132,096\n",
            "      BatchNorm2d-14             [-1, 64, 4, 4]             128\n",
            "  ConvTranspose2d-15             [-1, 32, 7, 7]          18,464\n",
            "      BatchNorm2d-16             [-1, 32, 7, 7]              64\n",
            "  ConvTranspose2d-17           [-1, 16, 14, 14]           4,624\n",
            "      BatchNorm2d-18           [-1, 16, 14, 14]              32\n",
            "  ConvTranspose2d-19            [-1, 1, 28, 28]             145\n",
            "================================================================\n",
            "Total params: 323,265\n",
            "Trainable params: 323,265\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 1.23\n",
            "Estimated Total Size (MB): 1.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "net = VarAutoEncoder(32).to(device) # you need to send the model to the devoic\n",
        "\n",
        "num_epochs = 30\n",
        "lr = 0.0001\n",
        "mm = 0.5\n",
        "optimizer = optim.Adam(net.parameters(), lr = lr)\n",
        "ls = []\n",
        "#(reconstruction loss )+(regulaztion)\n",
        "def var_loss(Xhat, X, u, logvar): \n",
        "  KLD_WEIGHT = 0.0012\n",
        "  term1 = F.mse_loss(Xhat, X) #reconstruction loss mean sqaured error\n",
        "  term2 = torch.mean(torch.sum(0.5*(1+logvar - torch.exp(logvar) - u**2), axis = 1), axis =0)\n",
        "  return (1- KLD_WEIGHT)* term1 - KLD_WEIGHT*term2 #we weight them what do i care more about to give more wight\n",
        "torch.Size([64, 1, 28, 28])\n",
        "torch.Size([28, 28])\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  net.train()\n",
        "  total_loss = 0\n",
        "  for batch in train_loader:\n",
        "    \n",
        "    X = batch[0].to(device)\n",
        "    print(\"hi\")\n",
        "    print(X.shape)\n",
        "    ex, z,Xhat, u, logvar = net(X)\n",
        "    loss = var_loss(Xhat, X,u, logvar )\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(epoch, total_loss)\n",
        "\n",
        "  ls.append(total_loss)\n",
        "\n",
        "plt.plot(ls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "CIM4pPpgtXFZ",
        "outputId": "c286bc6a-5fec-4774-c114-8e8d61a04494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "torch.Size([1, 28, 28])\n",
            "i am here\n",
            "torch.Size([1, 1, 28, 28])\n",
            "i am here2\n",
            "i am here3\n",
            "i am here5\n",
            "here is the shape of it \n",
            "torch.Size([1, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-a6f69716bc64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-9621cbe18f6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i am here99\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-9621cbe18f6d>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         )\n\u001b[1;32m   2447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     return torch.batch_norm(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 128])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = VarAutoEncoder(3).to(device) # you need to send the model to the devoic\n",
        "net.eval() #no using of the mean of the sample use the one compute intraing \n",
        "#take a random z and then decode that z \n",
        "z = torch.randn(64,3).to(device) #64 vacotrs with size of 32 in a one same as the  laten sizze of the image \n",
        "Xhat = net.decoder(z) #64*1*28*28\n"
      ],
      "metadata": {
        "id": "nVJiT_Scvnu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Xhat[0, 0]\n",
        "print(Xhat.shape, img.shape, img.dtype)\n",
        "plt.imshow(img.detach().cpu().numpy(), cmap='gray')"
      ],
      "metadata": {
        "id": "iIL5O4OF23sB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}